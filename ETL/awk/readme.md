# ETL процессы (awk, sed)
[awk. Удаление строк по условию](#awk_del_if)

[awk. Объединение значений в INSERT](#awk_insert)

[sed. Работа с текстом по условию](#sed_regex)

## <a id="awk_del_if">awk. Удаление строк по условию</a>
Допустим есть некий CSV\TXT файл, в котором содержится множество столбцов, разделитель — знак табуляции (\t) нам необходимо проверить не пустые ли определенные столбцы, и создать новый файл, где строки с пустыми заданными столбцами пропускаются
```bash
awk -F'\t' '{ if ($6 != "\\N" && $7 != "\\N" && $8 != "\\N") print $0; }' src.txt > dst.txt
```
в данном примере проверяется отличны ли столбцы 6, 7, 8 от значения \N в файле src.txt, если истина, то ВСЯ строка добавляется в файл dst.txt. Поскольку копируется строка целиком ($0), то разделители скопируются по умолчанию (как в файле). Но если нам нужен специфический, разделитель, например табуляция, то смотрим ниже.

Если нам необходимо вывести в форматированный файл не все столбцы из 
файла, а только некоторые, то команда выше будет иметь вид:
```bash
awk -F'\t' 'BEGIN { OFS="\t" } { if ($6 != "\\N" && $7 != "\\N" && $8 != "\\N") print $6, $7, $8, $9, $10, $11, $12, $13, $14, $19, $20, $21, $23, $33, $36, $37, $39, $41, $42}' src.txt > dst.txt
```
В приведенном примере проверяется тоже условие, что и выше, только выводится в файл dst.txt не все столбцы, а имеющие номера с 6 по 14, с 19 по 21 и 23, 33, 36, 37, 39, 41, 42.

По умолчанию awk использует пробел в качестве разделителя для вывода (даже если входной разделитель задан с помощью -F). Это связано с тем, что параметр OFS (Output Field Separator), отвечающий за разделитель выходных полей, по умолчанию установлен в значение пробела. Чтобы указать, что разделителем в выходных данных должна быть табуляция, нужно явно задать OFS='\t' в секции BEGIN.

## <a id="awk_insert">awk. Объединение значений в INSERT</a>

Допустим есть некий дамп базы MySQL, в котором содержится множество строк вида:
```SQL
INSERT IGNORE INTO `tablename` VALUES (1, 2, 3);
INSERT IGNORE INTO `tablename` VALUES (1, 2, 3);
INSERT IGNORE INTO `tablename` VALUES (1, 2, 3);
```
Из-за того, что VALUES не объединены, импорт данных будет происходить крайне медленно, поэтому лучше произвести объединение значений, например по 500 за один INSERT.
Создадим скрипт, который будет решать эту задачу:
```bash
#!/bin/bash

# Входной файл с дампом
input_file="dump.sql"
# Выходной файл с оптимизированным дампом
output_file="optimized_dump.sql"
# Максимальное количество значений в одном INSERT
max_values=500
# Обработка файла с помощью awk
awk -v max_values="$max_values" '
BEGIN {
    # Инициализация переменных
    table_name = "";
    values = "";
    count = 0;
}
{
    # Извлечение имени таблицы
    if ($0 ~ /^INSERT IGNORE INTO/) {
        if (table_name == "") {
            split($0, arr, "`");
            table_name = arr[2];
        }
        # Извлечение значений из строки
        match($0, /\(.*\)/);
        value = substr($0, RSTART, RLENGTH);
        if (values != "") {
            values = values "," value;
        } else {
            values = value;
        }
        count++;
        # Если достигнут лимит значений, формируем новый INSERT
        if (count % max_values == 0) {
            print "INSERT IGNORE INTO `" table_name "` VALUES " values ";";
            values = "";
        }
    }
}
END {
    # Формирование последнего INSERT, если остались значения
    if (values != "") {
        print "INSERT IGNORE INTO `" table_name "` VALUES " values ";";
    }
}
' "$input_file" > "$output_file"

echo "Оптимизированный дамп сохранен в $output_file"
```

## <a id="sed_regex">sed. Работа с текстом по условию</a>
### Примеры применения sed
|Команда|Описание|
|-|-|
|sed -i '751038d' file.txt|удалить строку № 751038 и обновить файл|
|cat file.txt \| sed 's/ 12:00:00 AM//g' > file2.txt|заменить "12:00:00 AM" на "" (пусто) и вывести в file2.txt|
|cat file.txt \| tail -n10 \| sed s/[^:]//g \| awk '{ print length }'|вывести построчно количество символов ":"|
|sed '1,/sourcetable/d' file.sql > new.sql|удалить все строки с 1й до слова "sourcetable" и сохранить в new.sql|
|sed -r 's/BLABLABLA.+//'|удалить все после BLABLABLA|
|sed 's/;[^;]*;[^;]*$//g'|удалить все после 2го ; с конца, например "1;2;3;4;5" -> "1;2;3"|
|sed -E 's/^[^;]*;+//g'|удалить все до 1го ; сначала, например "1;2;3" -> "2;3"|
|sed -e "s/^.//;s/.$//"|удалить первый и последний символ строки|
|sed -i -r -z 's/\x0d\x0a//g' 1.part_aa|удалить возврат каретки cp1251|

Если нужно обработать большого объема файл, то можно разбить его на несколько частей, произвести обработку sed’ом, и потом обратно склеить, например, создадим файл bash-скрипта и выполним его
```bash
#!/bin/bash
split -C 100M somefile.csv part_
for file in part_*; do
	sed -i -r -z 's/\x0a/#/g' "$file"
	sed -i 's/"#/"\n/g' "$file"
done
```
Данный скрипт разбивает файл somefile.csv на части, по 100 Мб, имена файлов имеют вид part_aa, part_ab, … . Затем, перебираются все эти файлы, в которых символ 0A (hex), заменяется на символ #, затем в этом же файле символ # меняется на символ конца строки \n.
Склеить все части можем командой:
```bash
cat part_* > orders_full.csv
```
В приведенном примере не используется разбивка файла построчно, т.к. из-за специфической кодировки, отсутствует символ конца строки (\n). Поэтому файл режется по объему.